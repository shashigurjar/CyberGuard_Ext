{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNkKdlPwbeHp"
      },
      "source": [
        "# DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywIyAop3kE55",
        "outputId": "0743f917-eab2-426c-c5c1-41b0aa4cb647"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyzbar in /usr/local/lib/python3.11/dist-packages (0.1.9)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.11/dist-packages (0.25.2)\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: python-whois in /usr/local/lib/python3.11/dist-packages (0.9.5)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.11/dist-packages (5.3.0)\n",
            "Requirement already satisfied: qrcode[pil] in /usr/local/lib/python3.11/dist-packages (8.2)\n",
            "Requirement already satisfied: pillow>=9.1.0 in /usr/local/lib/python3.11/dist-packages (from qrcode[pil]) (11.2.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: scipy>=1.11.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (1.15.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (3.4.2)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (2025.5.21)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image) (0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from tldextract) (3.10)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from tldextract) (2.32.3)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.11/dist-packages (from tldextract) (2.1.0)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.11/dist-packages (from tldextract) (3.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.1.0->tldextract) (2025.4.26)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyzbar opencv-python qrcode[pil] numpy matplotlib scikit-image pytesseract python-whois tldextract"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8kXrW9vlkVHt",
        "outputId": "52a54239-654d-445a-b59c-87cb6fd77641"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "zbar-tools is already the newest version (0.23.92-4build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 37 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get install -y zbar-tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "MH_QlwxMitAm"
      },
      "outputs": [],
      "source": [
        "# QR CONTENT AND URL EXTRACTION\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "from pyzbar.pyzbar import decode\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def extract_qr_content(image_path):\n",
        "    \"\"\"\n",
        "    Robust QR code content extraction with multiple fallbacks\n",
        "    Returns:\n",
        "    - content (str): Extracted text/URL if successful\n",
        "    - None: If extraction fails\n",
        "    \"\"\"\n",
        "    # Method 1: Try pyzbar with various pre-processing techniques\n",
        "    img = cv2.imread(image_path)\n",
        "\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not load image from {image_path}\")\n",
        "        return None\n",
        "\n",
        "    # Try different pre-processing combinations\n",
        "    processing_combinations = [\n",
        "        {'gray': True, 'blur': False, 'thresh': False},\n",
        "        {'gray': True, 'blur': True, 'thresh': False},\n",
        "        {'gray': True, 'blur': True, 'thresh': True},\n",
        "        {'gray': False, 'blur': False, 'thresh': False}\n",
        "    ]\n",
        "\n",
        "    for params in processing_combinations:\n",
        "        processed = img.copy()\n",
        "\n",
        "        # Convert to grayscale\n",
        "        if params['gray'] and len(processed.shape) == 3:\n",
        "            processed = cv2.cvtColor(processed, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Apply blur\n",
        "        if params['blur']:\n",
        "            processed = cv2.GaussianBlur(processed, (3, 3), 0)\n",
        "\n",
        "        # Apply threshold\n",
        "        if params['thresh']:\n",
        "            _, processed = cv2.threshold(processed, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "\n",
        "        # Try decoding\n",
        "        decoded = decode(processed)\n",
        "        if decoded:\n",
        "            try:\n",
        "                content = decoded[0].data.decode('utf-8')\n",
        "                if content.strip():\n",
        "                    return content\n",
        "            except UnicodeDecodeError:\n",
        "                try:\n",
        "                    content = decoded[0].data.decode('latin-1')\n",
        "                    if content.strip():\n",
        "                        return content\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "    # Method 2: If pyzbar fails, try OpenCV's QRCodeDetector\n",
        "    qr_detector = cv2.QRCodeDetector()\n",
        "    retval, decoded_info, points, straight_qrcode = qr_detector.detectAndDecodeMulti(img)\n",
        "\n",
        "    if retval and decoded_info:\n",
        "        for content in decoded_info:\n",
        "            if content.strip():\n",
        "                return content\n",
        "\n",
        "    # Method 3: As last resort, try OCR (pytesseract)\n",
        "    try:\n",
        "        pytesseract.pytesseract.tesseract_cmd = r'/usr/bin/tesseract'\n",
        "        content = pytesseract.image_to_string(Image.open(image_path))\n",
        "        if content.strip():\n",
        "            # Try to find URL patterns in OCR output\n",
        "            url_match = re.search(r'(https?://\\S+|www\\.\\S+)', content)\n",
        "            if url_match:\n",
        "                return url_match.group(0)\n",
        "            return content\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def extract_clean_url(qr_data):\n",
        "\n",
        "    if pd.isna(qr_data) or not isinstance(qr_data, str):\n",
        "        return None\n",
        "\n",
        "    # Remove the leading number and whitespace\n",
        "    url_match = re.search(r'(https?://\\S+)', qr_data)\n",
        "\n",
        "    if url_match:\n",
        "        url = url_match.group(1)\n",
        "\n",
        "        url = url.split(' ')[0]\n",
        "        url = url.split('\\n')[0]\n",
        "        url = url.strip()\n",
        "\n",
        "        if '...' in url:\n",
        "            url = url.replace('...', '')\n",
        "\n",
        "        return url\n",
        "\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pSmo4GeBx7SJ"
      },
      "outputs": [],
      "source": [
        "# URL DATA EXTRACTION\n",
        "\n",
        "import re\n",
        "import numpy as np\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import ssl\n",
        "import socket\n",
        "from datetime import datetime\n",
        "import whois\n",
        "from cryptography import x509\n",
        "from cryptography.hazmat.backends import default_backend\n",
        "import tldextract\n",
        "import idna\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "def check_ssl_cert(url):\n",
        "    try:\n",
        "        parsed_url = urlparse(url)\n",
        "        host = parsed_url.hostname\n",
        "        port = 443\n",
        "        context = ssl.create_default_context()\n",
        "\n",
        "        with socket.create_connection((host, port), timeout=5) as sock:\n",
        "            with context.wrap_socket(sock, server_hostname=host) as ssock:\n",
        "                cert_der = ssock.getpeercert(binary_form=True)\n",
        "                cert = x509.load_der_x509_certificate(cert_der, default_backend())\n",
        "\n",
        "                ssl_valid = 1\n",
        "                ssl_self_signed = 1 if cert.issuer == cert.subject else 0\n",
        "\n",
        "                # Fixed datetime comparison\n",
        "                now = datetime.now(timezone.utc)\n",
        "                validity = cert.not_valid_after_utc - datetime.now(timezone.utc)\n",
        "                ssl_days_left = validity.days if validity.days > 0 else 0\n",
        "\n",
        "                return ssl_valid, ssl_self_signed, ssl_days_left\n",
        "    except Exception as e:\n",
        "        return 0, 0, 0\n",
        "\n",
        "def get_whois_features(domain):\n",
        "    features = {\n",
        "        'domain_age_days': -1,\n",
        "        'domain_expiry_days': -1,\n",
        "        'domain_registered': 0,\n",
        "        'domain_country': '',\n",
        "        'has_whois_info': 0,\n",
        "        'registrar': '',\n",
        "        'name_servers_count': 0\n",
        "    }\n",
        "\n",
        "    try:\n",
        "        info = whois.whois(domain)\n",
        "        features['has_whois_info'] = 1\n",
        "\n",
        "        # Handle dates\n",
        "        creation_date = info.creation_date\n",
        "        expiration_date = info.expiration_date\n",
        "\n",
        "        if isinstance(creation_date, list):\n",
        "            creation_date = creation_date[0]\n",
        "        if isinstance(expiration_date, list):\n",
        "            expiration_date = expiration_date[0]\n",
        "\n",
        "        if creation_date and isinstance(creation_date, datetime):\n",
        "            features['domain_age_days'] = (datetime.utcnow() - creation_date).days\n",
        "        if expiration_date and isinstance(expiration_date, datetime):\n",
        "            features['domain_expiry_days'] = (expiration_date - datetime.utcnow()).days\n",
        "\n",
        "        # Additional WHOIS features\n",
        "        features['domain_registered'] = 1 if creation_date else 0\n",
        "        features['registrar'] = info.registrar if info.registrar else ''\n",
        "        features['name_servers_count'] = len(info.name_servers) if info.name_servers else 0\n",
        "        features['domain_country'] = info.country if info.country else ''\n",
        "\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    return features\n",
        "\n",
        "def get_tld_features(domain):\n",
        "    extracted = tldextract.extract(domain)\n",
        "    return {\n",
        "        'subdomain_count': len(extracted.subdomain.split('.')),\n",
        "        'tld': extracted.suffix,\n",
        "        'domain_part_count': len(extracted.subdomain.split('.')) + 2  # subdomain + domain + suffix\n",
        "    }\n",
        "\n",
        "def is_shortener(url):\n",
        "    shorteners = {'bit.ly', 'goo.gl', 'tinyurl.com', 'ow.ly', 't.co', 'is.gd'}\n",
        "    return 1 if any(s in url for s in shorteners) else 0\n",
        "\n",
        "def entropy(s):\n",
        "    p, lns = np.unique(list(s), return_counts=True)\n",
        "    return -np.sum((lns/lns.sum()) * np.log2(lns/lns.sum()))\n",
        "\n",
        "def extract_url_features(URL):\n",
        "    features = {}\n",
        "\n",
        "    # Basic URL features\n",
        "    features['URL_length'] = len(URL)\n",
        "    features['num_dots'] = URL.count('.')\n",
        "    features['num_hyphens'] = URL.count('-')\n",
        "    features['num_slashes'] = URL.count('/')\n",
        "    features['num_question_marks'] = URL.count('?')\n",
        "    features['num_equals'] = URL.count('=')\n",
        "    features['num_at'] = URL.count('@')\n",
        "    features['has_ip'] = 1 if re.match(r\"^(https?:\\/\\/)?(\\d{1,3}\\.){3}\\d{1,3}\", URL) else 0\n",
        "\n",
        "    # Parsed components\n",
        "    parsed = urlparse(URL)\n",
        "    domain = parsed.netloc\n",
        "    path = parsed.path\n",
        "    query = parsed.query\n",
        "\n",
        "    # Domain analysis\n",
        "    features['domain_length'] = len(domain)\n",
        "    tld_features = get_tld_features(domain)\n",
        "    features.update(tld_features)\n",
        "    features['is_idn'] = 1 if 'xn--' in domain else 0  # Internationalized domain name\n",
        "\n",
        "    # Path analysis\n",
        "    features['path_length'] = len(path)\n",
        "    features['path_depth'] = path.count('/')\n",
        "    features['file_extension'] = 1 if '.' in path.split('/')[-1] else 0\n",
        "\n",
        "    # Query parameters analysis\n",
        "    params = parse_qs(query)\n",
        "    features['num_parameters'] = len(params)\n",
        "    sensitive_params = {'password', 'login', 'user', 'creditcard'}\n",
        "    features['sensitive_params'] = sum(1 for p in params if p.lower() in sensitive_params)\n",
        "\n",
        "    # Security features\n",
        "    features['uses_https'] = 1 if parsed.scheme == 'https' else 0\n",
        "    ssl_valid, ssl_self_signed, ssl_days_left = check_ssl_cert(URL)\n",
        "    features.update({\n",
        "        'ssl_cert_valid': ssl_valid,\n",
        "        'ssl_self_signed': ssl_self_signed,\n",
        "        'ssl_days_left': ssl_days_left\n",
        "    })\n",
        "\n",
        "    # Content features\n",
        "    features['entropy'] = entropy(URL)\n",
        "    features['is_shortened'] = is_shortener(URL)\n",
        "    suspicious_keywords = ['login', 'verify', 'secure', 'account', 'update',\n",
        "                         'bank', 'paypal', 'signin', 'confirm', 'password']\n",
        "    features['suspicious_keywords'] = sum(1 for word in suspicious_keywords if word in URL.lower())\n",
        "\n",
        "    # WHOIS features\n",
        "    whois_data = get_whois_features(domain)\n",
        "    features.update(whois_data)\n",
        "\n",
        "    # Additional features\n",
        "    features['non_standard_port'] = 1 if parsed.port not in [None, 80, 443] else 0\n",
        "    features['hex_chars'] = len(re.findall(r'%[0-9a-fA-F]{2}', URL))\n",
        "    features['redirects'] = len(re.findall('//', URL)) - 1\n",
        "\n",
        "    # IP and network features\n",
        "    try:\n",
        "        ip = socket.gethostbyname(domain)\n",
        "        features['ip_private'] = 1 if ip.startswith(('10.', '172.', '192.168.')) else 0\n",
        "    except:\n",
        "        features['ip_private'] = 0\n",
        "\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A-OzBBECjo2M",
        "outputId": "3d2e446c-83a6-46c1-9251-aed513a7200a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Version 1 benign:  96%|█████████▌| 48/50 [01:04<00:02,  1.02s/it]2025-06-02 05:26:56,949 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 1 benign: 100%|██████████| 50/50 [01:16<00:00,  1.53s/it]\n",
            "Version 1 malicious:  36%|███▌      | 18/50 [00:57<00:59,  1.85s/it]2025-06-02 05:27:57,048 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "Version 1 malicious:  42%|████▏     | 21/50 [01:02<00:48,  1.68s/it]2025-06-02 05:28:11,467 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 1 malicious:  88%|████████▊ | 44/50 [02:03<00:08,  1.41s/it]2025-06-02 05:29:12,200 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 1 malicious: 100%|██████████| 50/50 [02:27<00:00,  2.94s/it]\n",
            "Version 2 benign:   6%|▌         | 3/50 [00:03<00:58,  1.24s/it]2025-06-02 05:29:39,626 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 2 benign:  38%|███▊      | 19/50 [00:34<00:29,  1.05it/s]2025-06-02 05:30:10,707 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 2 benign: 100%|██████████| 50/50 [01:27<00:00,  1.75s/it]\n",
            "Version 2 malicious:  22%|██▏       | 11/50 [00:11<00:39,  1.02s/it]2025-06-02 05:31:19,613 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 2 malicious:  48%|████▊     | 24/50 [00:52<00:39,  1.50s/it]2025-06-02 05:31:56,445 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 2 malicious:  54%|█████▍    | 27/50 [01:12<01:52,  4.89s/it]2025-06-02 05:32:17,062 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 2 malicious:  60%|██████    | 30/50 [01:25<01:13,  3.68s/it]2025-06-02 05:32:19,742 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "Version 2 malicious:  76%|███████▌  | 38/50 [01:44<00:22,  1.91s/it]2025-06-02 05:32:47,852 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 2 malicious: 100%|██████████| 50/50 [02:17<00:00,  2.74s/it]\n",
            "Version 3 benign:  44%|████▍     | 22/50 [00:29<00:29,  1.07s/it]2025-06-02 05:33:50,993 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 3 benign:  74%|███████▍  | 37/50 [00:54<00:13,  1.03s/it]2025-06-02 05:34:15,909 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 3 benign: 100%|██████████| 50/50 [01:17<00:00,  1.54s/it]\n",
            "Version 3 malicious:  14%|█▍        | 7/50 [00:19<03:18,  4.61s/it]2025-06-02 05:34:49,282 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "Version 3 malicious:  38%|███▊      | 19/50 [00:54<02:05,  4.06s/it]2025-06-02 05:35:33,956 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 3 malicious:  46%|████▌     | 23/50 [01:08<01:14,  2.75s/it]2025-06-02 05:35:47,452 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 3 malicious: 100%|██████████| 50/50 [02:24<00:00,  2.90s/it]\n",
            "Version 4 benign:  20%|██        | 10/50 [00:09<00:35,  1.13it/s]2025-06-02 05:37:14,903 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 4 benign:  36%|███▌      | 18/50 [00:31<00:50,  1.59s/it]2025-06-02 05:37:35,829 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 4 benign:  56%|█████▌    | 28/50 [01:11<02:01,  5.51s/it]2025-06-02 05:38:15,986 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 4 benign:  58%|█████▊    | 29/50 [01:22<02:29,  7.14s/it]2025-06-02 05:38:26,626 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 4 benign:  60%|██████    | 30/50 [01:32<02:43,  8.17s/it]2025-06-02 05:38:37,383 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 4 benign:  76%|███████▌  | 38/50 [01:55<00:25,  2.13s/it]2025-06-02 05:39:00,471 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 4 benign: 100%|██████████| 50/50 [02:17<00:00,  2.76s/it]\n",
            "Version 4 malicious:  30%|███       | 15/50 [00:43<01:39,  2.83s/it]2025-06-02 05:40:06,305 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 4 malicious:  70%|███████   | 35/50 [01:35<00:19,  1.28s/it]2025-06-02 05:40:58,594 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 4 malicious:  72%|███████▏  | 36/50 [01:46<00:58,  4.17s/it]2025-06-02 05:41:09,100 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 4 malicious:  78%|███████▊  | 39/50 [01:59<00:40,  3.67s/it]2025-06-02 05:41:12,736 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "Version 4 malicious: 100%|██████████| 50/50 [02:11<00:00,  2.63s/it]\n",
            "Version 5 benign:  48%|████▊     | 24/50 [00:25<00:27,  1.05s/it]2025-06-02 05:42:00,475 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 5 benign: 100%|██████████| 50/50 [01:12<00:00,  1.44s/it]\n",
            "Version 5 malicious:   0%|          | 0/50 [00:00<?, ?it/s]2025-06-02 05:42:47,260 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 5 malicious:   8%|▊         | 4/50 [00:14<02:06,  2.75s/it]2025-06-02 05:43:01,842 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 5 malicious:  30%|███       | 15/50 [01:02<01:25,  2.44s/it]2025-06-02 05:43:50,051 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 5 malicious:  72%|███████▏  | 36/50 [01:55<00:19,  1.38s/it]2025-06-02 05:44:33,751 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "Version 5 malicious:  74%|███████▍  | 37/50 [01:57<00:18,  1.40s/it]2025-06-02 05:44:35,093 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "Version 5 malicious:  90%|█████████ | 45/50 [02:07<00:06,  1.38s/it]2025-06-02 05:44:55,602 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 5 malicious: 100%|██████████| 50/50 [02:34<00:00,  3.09s/it]\n",
            "Version 6 benign:   8%|▊         | 4/50 [00:05<01:02,  1.35s/it]2025-06-02 05:45:27,971 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 6 benign:  28%|██▊       | 14/50 [00:27<00:42,  1.19s/it]2025-06-02 05:45:49,874 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 6 benign: 100%|██████████| 50/50 [01:18<00:00,  1.57s/it]\n",
            "Version 6 malicious:  20%|██        | 10/50 [00:30<00:54,  1.36s/it]2025-06-02 05:47:11,918 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 6 malicious:  24%|██▍       | 12/50 [00:42<02:03,  3.24s/it]2025-06-02 05:47:23,486 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 6 malicious:  26%|██▌       | 13/50 [00:53<03:24,  5.52s/it]2025-06-02 05:47:24,799 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "Version 6 malicious:  88%|████████▊ | 44/50 [02:24<00:17,  2.89s/it]2025-06-02 05:48:56,417 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "Version 6 malicious: 100%|██████████| 50/50 [02:32<00:00,  3.05s/it]\n",
            "Version 7 benign: 100%|██████████| 50/50 [01:10<00:00,  1.40s/it]\n",
            "Version 7 malicious:  48%|████▊     | 24/50 [01:35<00:41,  1.59s/it]2025-06-02 05:52:00,441 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 7 malicious:  72%|███████▏  | 36/50 [02:03<00:24,  1.77s/it]2025-06-02 05:52:28,874 - whois.whois - ERROR - Error trying to connect to socket: closing socket - timed out\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - timed out\n",
            "Version 7 malicious:  86%|████████▌ | 43/50 [02:35<00:20,  2.91s/it]2025-06-02 05:52:51,107 - whois.whois - ERROR - Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "ERROR:whois.whois:Error trying to connect to socket: closing socket - [Errno 111] Connection refused\n",
            "Version 7 malicious: 100%|██████████| 50/50 [02:45<00:00,  3.30s/it]\n"
          ]
        }
      ],
      "source": [
        "# URL FEATURES CSV\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def process_dataset(base_path):\n",
        "    all_features = []\n",
        "\n",
        "    for version in range(1, 8):\n",
        "        version_path = os.path.join(base_path, f'version_{version}')\n",
        "\n",
        "        for label in ['benign', 'malicious']:\n",
        "            folder_path = os.path.join(version_path, label)\n",
        "\n",
        "            for img_file in tqdm(os.listdir(folder_path), desc=f'Version {version} {label}'):\n",
        "                if img_file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                    img_path = os.path.join(folder_path, img_file)\n",
        "\n",
        "                    # Extract features\n",
        "                    features = {'version': version, 'label': 0 if label == 'benign' else 1}\n",
        "\n",
        "\n",
        "                    # If QR contains URL, extract URL features\n",
        "                    qr_content = extract_qr_content(img_path)\n",
        "                    cleaned_url = extract_clean_url(qr_content)\n",
        "                    if cleaned_url:\n",
        "                        features.update(extract_url_features(cleaned_url))\n",
        "\n",
        "                    all_features.append(features)\n",
        "\n",
        "    return pd.DataFrame(all_features)\n",
        "\n",
        "# Define paths\n",
        "base_path = '/content/drive/MyDrive/CyberGuard/qrCodes'\n",
        "df = process_dataset(base_path)\n",
        "\n",
        "# Save features\n",
        "df.to_csv('qr_code_url_features.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "dsqdRPMsqR6z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cd350e3-06d0-403b-bf3d-7434e216eec7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "38\n",
            "Index(['version', 'label', 'URL_length', 'num_dots', 'num_hyphens',\n",
            "       'num_slashes', 'num_question_marks', 'num_equals', 'num_at', 'has_ip',\n",
            "       'domain_length', 'subdomain_count', 'tld', 'domain_part_count',\n",
            "       'is_idn', 'path_length', 'path_depth', 'file_extension',\n",
            "       'num_parameters', 'sensitive_params', 'uses_https', 'ssl_cert_valid',\n",
            "       'ssl_self_signed', 'ssl_days_left', 'entropy', 'is_shortened',\n",
            "       'suspicious_keywords', 'domain_age_days', 'domain_expiry_days',\n",
            "       'domain_registered', 'domain_country', 'has_whois_info', 'registrar',\n",
            "       'name_servers_count', 'non_standard_port', 'hex_chars', 'redirects',\n",
            "       'ip_private'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(len(df.columns))\n",
        "print(df.columns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOADING IMAGES FOR CNN\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def load_qr_images(base_path, img_size=(128, 128)):\n",
        "    images = []\n",
        "    labels = []\n",
        "\n",
        "    for version in range(1, 8):  # version1 to version7\n",
        "        for label_name, label_value in [('benign', 0), ('malicious', 1)]:\n",
        "            folder_path = os.path.join(base_path, f\"version_{version}\", label_name)\n",
        "            for filename in os.listdir(folder_path):\n",
        "                if filename.endswith(\".png\"):\n",
        "                    img_path = os.path.join(folder_path, filename)\n",
        "                    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "                    if img is None:\n",
        "                        continue  # skip unreadable images\n",
        "                    img = cv2.resize(img, img_size)\n",
        "                    img = img.astype(\"float32\") / 255.0\n",
        "                    images.append(np.expand_dims(img, axis=-1))  # shape (H, W, 1)\n",
        "                    labels.append(label_value)\n",
        "\n",
        "    X = np.array(images)\n",
        "    y = np.array(labels)\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "qZxkL6sx8W8z"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "base_path = '/content/drive/MyDrive/CyberGuard/qrCodes'\n",
        "\n",
        "X_img, y_img = load_qr_images(base_path)\n",
        "\n",
        "print(\"Images shape:\", X_img.shape)\n",
        "print(\"Labels shape:\", y_img.shape)\n",
        "print(\"Class distribution:\", np.bincount(y_img))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E0cdTYvI8hIP",
        "outputId": "566b8aac-27f5-4059-f702-4c6fd461f432"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Images shape: (700, 128, 128, 1)\n",
            "Labels shape: (700,)\n",
            "Class distribution: [350 350]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CNc5cMNcD6M"
      },
      "source": [
        "# DATA PRE-PROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif\n",
        "\n",
        "def cast_to_int(X):\n",
        "    \"\"\"Casts input to integer type.\"\"\"\n",
        "    return X.astype(int)\n",
        "\n",
        "# 1. Define feature groups\n",
        "numeric_features = [\n",
        "    'URL_length', 'num_dots', 'num_hyphens', 'num_slashes',\n",
        "    'num_question_marks', 'num_equals', 'num_at', 'domain_length',\n",
        "    'subdomain_count', 'domain_part_count', 'path_length', 'path_depth',\n",
        "    'num_parameters', 'ssl_days_left', 'entropy',\n",
        "    'domain_age_days', 'domain_expiry_days', 'name_servers_count', 'redirects'\n",
        "]\n",
        "\n",
        "boolean_features = [\n",
        "    'has_ip', 'is_idn', 'uses_https', 'ssl_cert_valid', 'ssl_self_signed',\n",
        "    'is_shortened', 'domain_registered', 'has_whois_info', 'non_standard_port',\n",
        "    'hex_chars', 'ip_private'\n",
        "]\n",
        "\n",
        "categorical_features = [\n",
        "    'tld', 'file_extension', 'domain_country'\n",
        "]\n",
        "\n",
        "# 2. Build individual pipelines\n",
        "numeric_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "boolean_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value=0)),\n",
        "    ('cast', FunctionTransformer(func=cast_to_int))\n",
        "])\n",
        "\n",
        "categorical_pipeline = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "\n",
        "# 3. Combine into a ColumnTransformer\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "    ('num', numeric_pipeline, numeric_features),\n",
        "    ('bool', boolean_pipeline, boolean_features),\n",
        "    ('cat', categorical_pipeline, categorical_features)\n",
        "])\n",
        "\n",
        "# 4. Fit and transform\n",
        "df = pd.read_csv('qr_code_url_features.csv')\n",
        "X = df.drop(columns=['label'])\n",
        "y = df['label']\n",
        "X_preprocessed = preprocessor.fit_transform(X)\n",
        "\n",
        "# 5. PCA for dimensionality reduction\n",
        "# Keep components that explain 95% variance\n",
        "pca = PCA(n_components=0.95, random_state=42)\n",
        "X_pca = pca.fit_transform(X_preprocessed)\n",
        "\n",
        "# 6. SelectKBest for supervised feature selection\n",
        "# Using ANOVA F-test\n",
        "kbest = SelectKBest(score_func=f_classif, k=10)\n",
        "X_kbest = kbest.fit_transform(X_preprocessed, y)\n",
        "\n",
        "# 7. Retrieving feature names after ColumnTransformer + OneHotEncoder\n",
        "ohe = preprocessor.named_transformers_['cat']['onehot']\n",
        "cat_names = ohe.get_feature_names_out(categorical_features)\n",
        "all_feature_names = numeric_features + boolean_features + list(cat_names)\n",
        "selected_indices = kbest.get_support(indices=True)\n",
        "selected_feature_names = [all_feature_names[i] for i in selected_indices]\n",
        "print('Selected features:', selected_feature_names)\n",
        "\n",
        "\n",
        "X_url = X_kbest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOC7SYLU-6VO",
        "outputId": "a15b0bb2-b524-4fd4-d715-e41a570cc860"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Selected features: ['domain_length', 'ssl_days_left', 'domain_age_days', 'name_servers_count', 'uses_https', 'ssl_cert_valid', 'domain_registered', 'has_whois_info', 'domain_country_US', 'domain_country_missing']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:111: UserWarning: Features [ 6 18 19 20 23 27] are constant.\n",
            "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
            "  f = msb / msw\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpA_wdsLgod_"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# shuffle\n",
        "X_img, X_url, y = shuffle(X_img, X_url, y, random_state=42)\n",
        "\n",
        "# train-test split\n",
        "X_img_train, X_img_test, X_url_train, X_url_test, y_train, y_test = train_test_split(\n",
        "    X_img, X_url, y,\n",
        "    test_size=0.2,\n",
        "    stratify=y,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# scaling\n",
        "scaler = StandardScaler()\n",
        "X_url_train = scaler.fit_transform(X_url_train)\n",
        "X_url_test  = scaler.transform(X_url_test)\n",
        "\n",
        "\n",
        "# Define the CNN branch for image data\n",
        "image_input = Input(shape=(128, 128, 1), name='qr_image')\n",
        "x = Conv2D(32, (3, 3), activation='relu')(image_input)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Flatten()(x)\n",
        "cnn_output = Dense(64, activation='relu')(x)\n",
        "\n",
        "# Define the MLP branch for URL features\n",
        "url_input = Input(shape=(X_url_train.shape[1],), name='url_features') # Use the actual number of features\n",
        "y_mlp = Dense(32, activation='relu')(url_input)\n",
        "\n",
        "# Combine the branches\n",
        "combined = concatenate([cnn_output, y_mlp])\n",
        "\n",
        "# Final dense layers\n",
        "z = Dense(32, activation='relu')(combined)\n",
        "output = Dense(1, activation='sigmoid')(z) # Binary classification (benign/malicious)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs=[image_input, url_input], outputs=output)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "# fit hybrid model\n",
        "history = model.fit(\n",
        "    {\n",
        "      \"qr_image\":     X_img_train,\n",
        "      \"url_features\": X_url_train\n",
        "    },\n",
        "    y_train,\n",
        "    validation_split=0.1,   # 10% of train used for val\n",
        "    epochs=30,\n",
        "    batch_size=16,\n",
        "    callbacks=[\n",
        "      tf.keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        patience=5,\n",
        "        restore_best_weights=True\n",
        "      )\n",
        "    ]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 894
        },
        "id": "G2rfvvYKGw4J",
        "outputId": "c554e33d-6769-4de3-8bd3-b7e56660546f"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ qr_image            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m,  │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │ \u001b[38;5;34m1\u001b[0m)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m,  │        \u001b[38;5;34m320\u001b[0m │ qr_image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│                     │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m32\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m,    │     \u001b[38;5;34m18,496\u001b[0m │ max_pooling2d[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│                     │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m,    │          \u001b[38;5;34m0\u001b[0m │ conv2d_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)      │ \u001b[38;5;34m64\u001b[0m)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m57600\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ max_pooling2d_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ url_features        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │  \u001b[38;5;34m3,686,464\u001b[0m │ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │        \u001b[38;5;34m352\u001b[0m │ url_features[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],      │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │      \u001b[38;5;34m3,104\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m33\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ qr_image            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>,  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>,  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │ qr_image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>,    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │ max_pooling2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ max_pooling2d_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>,    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">57600</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ max_pooling2d_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ url_features        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,686,464</span> │ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">352</span> │ url_features[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],      │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,104</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,708,769\u001b[0m (14.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,708,769</span> (14.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m3,708,769\u001b[0m (14.15 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,708,769</span> (14.15 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 422ms/step - accuracy: 0.5702 - loss: 0.8528 - val_accuracy: 0.7857 - val_loss: 0.5551\n",
            "Epoch 2/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 413ms/step - accuracy: 0.8870 - loss: 0.3884 - val_accuracy: 0.7679 - val_loss: 0.5463\n",
            "Epoch 3/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 411ms/step - accuracy: 0.8884 - loss: 0.3133 - val_accuracy: 0.7857 - val_loss: 0.5882\n",
            "Epoch 4/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 435ms/step - accuracy: 0.9131 - loss: 0.2340 - val_accuracy: 0.7857 - val_loss: 0.6415\n",
            "Epoch 5/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 393ms/step - accuracy: 0.9341 - loss: 0.1688 - val_accuracy: 0.7857 - val_loss: 0.5892\n",
            "Epoch 6/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 398ms/step - accuracy: 0.9422 - loss: 0.1479 - val_accuracy: 0.7857 - val_loss: 0.5614\n",
            "Epoch 7/30\n",
            "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 347ms/step - accuracy: 0.9707 - loss: 0.0889 - val_accuracy: 0.7679 - val_loss: 0.5787\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, acc = model.evaluate(\n",
        "    {\n",
        "      \"qr_image\":     X_img_test,\n",
        "      \"url_features\": X_url_test\n",
        "    },\n",
        "    y_test\n",
        ")\n",
        "print(f\"Test loss: {loss:.4f}, Test accuracy: {acc:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRgPN97gMvUj",
        "outputId": "ff0b4735-d47f-41ff-a69a-c4d2b4a7d8ab"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 170ms/step - accuracy: 0.8749 - loss: 0.3983\n",
            "Test loss: 0.3827, Test accuracy: 0.8786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREDICTING ON NEW IMAGE"
      ],
      "metadata": {
        "id": "pM548YpuPJlk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"qr_code_url_features.csv\")\n",
        "\n",
        "def preprocess_image(img_path, img_size=(128, 128)):\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        print(f\"Error: Could not load image from {img_path}\")\n",
        "        return None\n",
        "    img = cv2.resize(img, img_size)\n",
        "    img = img.astype(\"float32\") / 255.0\n",
        "    img = np.expand_dims(img, axis=-1)  # (128, 128, 1)\n",
        "    img = np.expand_dims(img, axis=0)   # (1, 128, 128, 1)\n",
        "    return img\n",
        "\n",
        "test_img_path = \"qr-benign.png\"\n",
        "X_new_img = preprocess_image(test_img_path)\n",
        "\n",
        "if X_new_img is None:\n",
        "    print(\"Image loading failed. Exiting.\")\n",
        "    exit()\n",
        "\n",
        "X_new_url_features = {}\n",
        "\n",
        "qr_content = extract_qr_content(test_img_path)\n",
        "\n",
        "cleaned_url = extract_clean_url(qr_content)\n",
        "\n",
        "if cleaned_url:\n",
        "    X_new_url_features.update(extract_url_features(cleaned_url))\n",
        "\n",
        "training_columns = df.drop(columns=['label']).columns # Get columns from the training DataFrame 'df'\n",
        "X_new_url_df = pd.DataFrame([X_new_url_features], columns=training_columns)\n",
        "\n",
        "\n",
        "# Preprocess the URL features using the *trained* preprocessor\n",
        "X_new_url_preprocessed = preprocessor.transform(X_new_url_df)\n",
        "\n",
        "# Apply the SelectKBest transformation.\n",
        "X_new_url_final = kbest.transform(X_new_url_preprocessed)\n",
        "\n",
        "\n",
        "pred = model.predict({\n",
        "    \"qr_image\": X_new_img,\n",
        "    \"url_features\": X_new_url_final\n",
        "})\n",
        "\n",
        "print(f\"Malicious probability: {pred[0][0]:.4f}\")\n",
        "print(\"Prediction:\", \"Malicious\" if pred[0][0] >= 0.5 else \"Benign\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGlfOCfFOOns",
        "outputId": "2cd953c4-d092-4f94-c541-2900f85129a2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 225ms/step\n",
            "Malicious probability: 0.0186\n",
            "Prediction: Benign\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pyzbar import pyzbar\n",
        "from io import BytesIO\n",
        "\n",
        "def preprocess_image_array(img, img_size=(128, 128)):\n",
        "    \"\"\"Resize, normalize, and reshape a grayscale image array for model input.\"\"\"\n",
        "    img = cv2.resize(img, img_size)\n",
        "    img = img.astype(\"float32\") / 255.0\n",
        "    img = np.expand_dims(img, axis=-1)   # (H, W, 1)\n",
        "    img = np.expand_dims(img, axis=0)    # (1, H, W, 1)\n",
        "    return img\n",
        "\n",
        "def predict_qr_from_url(image_url,\n",
        "                        model,\n",
        "                        preprocessor,\n",
        "                        kbest,\n",
        "                        training_columns):\n",
        "    \"\"\"\n",
        "    Download an image from URL, discard non-QR images, extract features,\n",
        "    preprocess and predict using the hybrid model.\n",
        "    \"\"\"\n",
        "    # 1) Download image\n",
        "    resp = requests.get(image_url)\n",
        "    if resp.status_code != 200:\n",
        "        raise ValueError(f\"Failed to download image: HTTP {resp.status_code}\")\n",
        "    img_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
        "    img = cv2.imdecode(img_array, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise ValueError(\"Downloaded content is not a valid image\")\n",
        "\n",
        "    # 2) Decode QR codes\n",
        "    decoded_objs = pyzbar.decode(img)\n",
        "    if not decoded_objs:\n",
        "        return {\"error\": \"No QR code detected in image\"}\n",
        "\n",
        "    # 3) Extract QR content and URL features\n",
        "    qr_content = decoded_objs[0].data.decode(\"utf-8\")\n",
        "    cleaned_url = extract_clean_url(qr_content)\n",
        "    if not cleaned_url:\n",
        "        return {\"error\": \"Decoded QR has no valid URL\"}\n",
        "    url_features = extract_url_features(cleaned_url)\n",
        "\n",
        "    # 4) Prepare model inputs\n",
        "    X_img = preprocess_image_array(img)\n",
        "    X_url_df = pd.DataFrame([url_features], columns=training_columns)\n",
        "    X_url_pre = preprocessor.transform(X_url_df)\n",
        "    X_url_fin = kbest.transform(X_url_pre)\n",
        "\n",
        "    # 5) Predict\n",
        "    pred_prob = model.predict({\n",
        "        \"qr_image\": X_img,\n",
        "        \"url_features\": X_url_fin\n",
        "    })[0][0]\n",
        "\n",
        "    return {\n",
        "        \"malicious_probability\": float(pred_prob),\n",
        "        \"prediction\": \"Malicious\" if pred_prob >= 0.5 else \"Benign\"\n",
        "    }\n",
        "\n",
        "result = predict_qr_from_url(\n",
        "    \"https://letsenhance.io/static/73136da51c245e80edc6ccfe44888a99/1015f/MainBefore.jpg\",\n",
        "    model,\n",
        "    preprocessor,\n",
        "    kbest,\n",
        "    training_columns\n",
        ")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jSlTZqZL0SeH",
        "outputId": "cfea703d-de8e-4482-d977-8861ebcedce3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'error': 'No QR code detected in image'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = predict_qr_from_url(\n",
        "    \"https://docs.lightburnsoftware.com/legacy/img/QRCode/ExampleCode.png\",\n",
        "    model,\n",
        "    preprocessor,\n",
        "    kbest,\n",
        "    training_columns\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cP8AHXUSGt4X",
        "outputId": "1c780d77-babe-4fc1-c0e3-c253a6ab192c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "{'malicious_probability': 0.11023060232400894, 'prediction': 'Benign'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = predict_qr_from_url(\n",
        "    \"https://www.joydeepdeb.com/images/qr-code.jpg\",\n",
        "    model,\n",
        "    preprocessor,\n",
        "    kbest,\n",
        "    training_columns\n",
        ")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f82788df-099a-4341-be5a-31ce2aac89ca",
        "id": "ri7wll25HVYL"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
            "{'malicious_probability': 0.26557496190071106, 'prediction': 'Benign'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "import joblib\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import model_from_json\n",
        "\n",
        "# Extract JSON architecture and weights from your trained Keras model\n",
        "model_json    = model.to_json()\n",
        "model_weights = model.get_weights()\n",
        "\n",
        "# Define the wrapper class\n",
        "class QRHybridPipeline:\n",
        "    def __init__(self, model_json, model_weights, preprocessor, kbest, training_columns):\n",
        "        # Keras pieces (JSON + weights)\n",
        "        self._model_json    = model_json\n",
        "        self._model_weights = model_weights\n",
        "\n",
        "        # Scikit-learn transformers\n",
        "        self.preprocessor     = preprocessor\n",
        "        self.kbest            = kbest\n",
        "\n",
        "        # Metadata\n",
        "        self.training_columns = training_columns\n",
        "\n",
        "        # Placeholder for reconstructed model\n",
        "        self.model = None\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Rebuilds and compiles the Keras model from JSON + weights.\"\"\"\n",
        "        if self.model is None:\n",
        "            self.model = model_from_json(self._model_json)\n",
        "            self.model.set_weights(self._model_weights)\n",
        "            self.model.compile(\n",
        "                optimizer=\"adam\",\n",
        "                loss=\"binary_crossentropy\",\n",
        "                metrics=[\"accuracy\"]\n",
        "            )\n",
        "        return self.model\n",
        "\n",
        "# Instantiate and pickle the pipeline wrapper\n",
        "pipeline = QRHybridPipeline(\n",
        "    model_json       = model_json,\n",
        "    model_weights    = model_weights,\n",
        "    preprocessor     = preprocessor,\n",
        "    kbest            = kbest,\n",
        "    training_columns = training_columns\n",
        ")\n",
        "\n",
        "with open(\"qr_hybrid_pipeline.pkl\", \"wb\") as f:\n",
        "    pickle.dump(pipeline, f)\n",
        "\n",
        "print(\"Saved unified pipeline to 'qr_hybrid_pipeline.pkl'\")\n"
      ],
      "metadata": {
        "id": "Kqso9j3FEtzK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bddfeccb-8c1c-4185-b560-a498deb8e4b4"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved unified pipeline to 'qr_hybrid_pipeline.pkl'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading and using the pipeline later\n",
        "with open(\"qr_hybrid_pipeline.pkl\", \"rb\") as f:\n",
        "    loaded_pipeline = pickle.load(f)\n",
        "\n",
        "# Rebuild the Keras model\n",
        "reconstructed_model = loaded_pipeline.load_model()\n",
        "\n",
        "# Access the preprocessor, k-best selector, and feature names\n",
        "reconstructed_preprocessor = loaded_pipeline.preprocessor\n",
        "reconstructed_kbest        = loaded_pipeline.kbest\n",
        "reconstructed_columns      = loaded_pipeline.training_columns\n",
        "\n",
        "print(\"Pipeline loaded:\")\n",
        "print(\"-\", reconstructed_model)\n",
        "print(\"-\", reconstructed_preprocessor)\n",
        "print(\"-\", reconstructed_kbest)\n",
        "print(\"-\", reconstructed_columns)"
      ],
      "metadata": {
        "id": "AxCv-woJGStB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2831d41-31db-42e2-b2f8-a93ee055baa1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pipeline loaded:\n",
            "- <Functional name=functional, built=True>\n",
            "- ColumnTransformer(transformers=[('num',\n",
            "                                 Pipeline(steps=[('imputer',\n",
            "                                                  SimpleImputer(strategy='median')),\n",
            "                                                 ('scaler', StandardScaler())]),\n",
            "                                 ['URL_length', 'num_dots', 'num_hyphens',\n",
            "                                  'num_slashes', 'num_question_marks',\n",
            "                                  'num_equals', 'num_at', 'domain_length',\n",
            "                                  'subdomain_count', 'domain_part_count',\n",
            "                                  'path_length', 'path_depth', 'num_parameters',\n",
            "                                  'ssl_days_left', 'entropy',...\n",
            "                                 ['has_ip', 'is_idn', 'uses_https',\n",
            "                                  'ssl_cert_valid', 'ssl_self_signed',\n",
            "                                  'is_shortened', 'domain_registered',\n",
            "                                  'has_whois_info', 'non_standard_port',\n",
            "                                  'hex_chars', 'ip_private']),\n",
            "                                ('cat',\n",
            "                                 Pipeline(steps=[('imputer',\n",
            "                                                  SimpleImputer(fill_value='missing',\n",
            "                                                                strategy='constant')),\n",
            "                                                 ('onehot',\n",
            "                                                  OneHotEncoder(handle_unknown='ignore',\n",
            "                                                                sparse_output=False))]),\n",
            "                                 ['tld', 'file_extension', 'domain_country'])])\n",
            "- SelectKBest()\n",
            "- Index(['version', 'URL_length', 'num_dots', 'num_hyphens', 'num_slashes',\n",
            "       'num_question_marks', 'num_equals', 'num_at', 'has_ip', 'domain_length',\n",
            "       'subdomain_count', 'tld', 'domain_part_count', 'is_idn', 'path_length',\n",
            "       'path_depth', 'file_extension', 'num_parameters', 'sensitive_params',\n",
            "       'uses_https', 'ssl_cert_valid', 'ssl_self_signed', 'ssl_days_left',\n",
            "       'entropy', 'is_shortened', 'suspicious_keywords', 'domain_age_days',\n",
            "       'domain_expiry_days', 'domain_registered', 'domain_country',\n",
            "       'has_whois_info', 'registrar', 'name_servers_count',\n",
            "       'non_standard_port', 'hex_chars', 'redirects', 'ip_private'],\n",
            "      dtype='object')\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}